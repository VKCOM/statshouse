// Copyright 2025 V Kontakte LLC
//
// This Source Code Form is subject to the terms of the Mozilla Public
// License, v. 2.0. If a copy of the MPL was not distributed with this
// file, You can obtain one at https://mozilla.org/MPL/2.0/.

// Code generated by vktl/cmd/tlgen2; DO NOT EDIT.
package internal

import (
	"github.com/VKCOM/statshouse/internal/vkgo/basictl"
)

var _ = basictl.NatWrite

type StatshouseSendSourceBucket2 struct {
	FieldsMask uint32
	Header     StatshouseCommonProxyHeader
	Owner      string // Conditional: item.FieldsMask.4
	Time       uint32
	// Historic (TrueType) // Conditional: item.FieldsMask.0
	// Spare (TrueType) // Conditional: item.FieldsMask.1
	BuildCommit            string
	BuildCommitDate        int32
	BuildCommitTs          uint32
	QueueSizeDisk          int32
	QueueSizeMemory        int32
	QueueSizeDiskSum       int32 // Conditional: item.FieldsMask.2
	QueueSizeMemorySum     int32 // Conditional: item.FieldsMask.2
	QueueSizeDiskUnsent    int32 // Conditional: item.FieldsMask.3
	QueueSizeDiskSumUnsent int32 // Conditional: item.FieldsMask.3
	OriginalSize           uint32
	CompressedData         string
	Sharding               int32 // Conditional: item.FieldsMask.5
}

func (StatshouseSendSourceBucket2) TLName() string { return "statshouse.sendSourceBucket2" }
func (StatshouseSendSourceBucket2) TLTag() uint32  { return 0x44575940 }

func (item *StatshouseSendSourceBucket2) SetOwner(v string) {
	item.Owner = v
	item.FieldsMask |= 1 << 4
}
func (item *StatshouseSendSourceBucket2) ClearOwner() {
	item.Owner = ""
	item.FieldsMask &^= 1 << 4
}
func (item StatshouseSendSourceBucket2) IsSetOwner() bool { return item.FieldsMask&(1<<4) != 0 }

func (item *StatshouseSendSourceBucket2) SetHistoric(v bool) {
	if v {
		item.FieldsMask |= 1 << 0
	} else {
		item.FieldsMask &^= 1 << 0
	}
}
func (item StatshouseSendSourceBucket2) IsSetHistoric() bool { return item.FieldsMask&(1<<0) != 0 }

func (item *StatshouseSendSourceBucket2) SetSpare(v bool) {
	if v {
		item.FieldsMask |= 1 << 1
	} else {
		item.FieldsMask &^= 1 << 1
	}
}
func (item StatshouseSendSourceBucket2) IsSetSpare() bool { return item.FieldsMask&(1<<1) != 0 }

func (item *StatshouseSendSourceBucket2) SetQueueSizeDiskSum(v int32) {
	item.QueueSizeDiskSum = v
	item.FieldsMask |= 1 << 2
}
func (item *StatshouseSendSourceBucket2) ClearQueueSizeDiskSum() {
	item.QueueSizeDiskSum = 0
	item.FieldsMask &^= 1 << 2
}
func (item StatshouseSendSourceBucket2) IsSetQueueSizeDiskSum() bool {
	return item.FieldsMask&(1<<2) != 0
}

func (item *StatshouseSendSourceBucket2) SetQueueSizeMemorySum(v int32) {
	item.QueueSizeMemorySum = v
	item.FieldsMask |= 1 << 2
}
func (item *StatshouseSendSourceBucket2) ClearQueueSizeMemorySum() {
	item.QueueSizeMemorySum = 0
	item.FieldsMask &^= 1 << 2
}
func (item StatshouseSendSourceBucket2) IsSetQueueSizeMemorySum() bool {
	return item.FieldsMask&(1<<2) != 0
}

func (item *StatshouseSendSourceBucket2) SetQueueSizeDiskUnsent(v int32) {
	item.QueueSizeDiskUnsent = v
	item.FieldsMask |= 1 << 3
}
func (item *StatshouseSendSourceBucket2) ClearQueueSizeDiskUnsent() {
	item.QueueSizeDiskUnsent = 0
	item.FieldsMask &^= 1 << 3
}
func (item StatshouseSendSourceBucket2) IsSetQueueSizeDiskUnsent() bool {
	return item.FieldsMask&(1<<3) != 0
}

func (item *StatshouseSendSourceBucket2) SetQueueSizeDiskSumUnsent(v int32) {
	item.QueueSizeDiskSumUnsent = v
	item.FieldsMask |= 1 << 3
}
func (item *StatshouseSendSourceBucket2) ClearQueueSizeDiskSumUnsent() {
	item.QueueSizeDiskSumUnsent = 0
	item.FieldsMask &^= 1 << 3
}
func (item StatshouseSendSourceBucket2) IsSetQueueSizeDiskSumUnsent() bool {
	return item.FieldsMask&(1<<3) != 0
}

func (item *StatshouseSendSourceBucket2) SetSharding(v int32) {
	item.Sharding = v
	item.FieldsMask |= 1 << 5
}
func (item *StatshouseSendSourceBucket2) ClearSharding() {
	item.Sharding = 0
	item.FieldsMask &^= 1 << 5
}
func (item StatshouseSendSourceBucket2) IsSetSharding() bool { return item.FieldsMask&(1<<5) != 0 }

func (item *StatshouseSendSourceBucket2) Reset() {
	item.FieldsMask = 0
	item.Header.Reset()
	item.Owner = ""
	item.Time = 0
	item.BuildCommit = ""
	item.BuildCommitDate = 0
	item.BuildCommitTs = 0
	item.QueueSizeDisk = 0
	item.QueueSizeMemory = 0
	item.QueueSizeDiskSum = 0
	item.QueueSizeMemorySum = 0
	item.QueueSizeDiskUnsent = 0
	item.QueueSizeDiskSumUnsent = 0
	item.OriginalSize = 0
	item.CompressedData = ""
	item.Sharding = 0
}

func (item *StatshouseSendSourceBucket2) Read(w []byte) (_ []byte, err error) {
	if w, err = basictl.NatRead(w, &item.FieldsMask); err != nil {
		return w, err
	}
	if w, err = item.Header.Read(w, item.FieldsMask); err != nil {
		return w, err
	}
	if item.FieldsMask&(1<<4) != 0 {
		if w, err = basictl.StringRead(w, &item.Owner); err != nil {
			return w, err
		}
	} else {
		item.Owner = ""
	}
	if w, err = basictl.NatRead(w, &item.Time); err != nil {
		return w, err
	}
	if w, err = basictl.StringRead(w, &item.BuildCommit); err != nil {
		return w, err
	}
	if w, err = basictl.IntRead(w, &item.BuildCommitDate); err != nil {
		return w, err
	}
	if w, err = basictl.NatRead(w, &item.BuildCommitTs); err != nil {
		return w, err
	}
	if w, err = basictl.IntRead(w, &item.QueueSizeDisk); err != nil {
		return w, err
	}
	if w, err = basictl.IntRead(w, &item.QueueSizeMemory); err != nil {
		return w, err
	}
	if item.FieldsMask&(1<<2) != 0 {
		if w, err = basictl.IntRead(w, &item.QueueSizeDiskSum); err != nil {
			return w, err
		}
	} else {
		item.QueueSizeDiskSum = 0
	}
	if item.FieldsMask&(1<<2) != 0 {
		if w, err = basictl.IntRead(w, &item.QueueSizeMemorySum); err != nil {
			return w, err
		}
	} else {
		item.QueueSizeMemorySum = 0
	}
	if item.FieldsMask&(1<<3) != 0 {
		if w, err = basictl.IntRead(w, &item.QueueSizeDiskUnsent); err != nil {
			return w, err
		}
	} else {
		item.QueueSizeDiskUnsent = 0
	}
	if item.FieldsMask&(1<<3) != 0 {
		if w, err = basictl.IntRead(w, &item.QueueSizeDiskSumUnsent); err != nil {
			return w, err
		}
	} else {
		item.QueueSizeDiskSumUnsent = 0
	}
	if w, err = basictl.NatRead(w, &item.OriginalSize); err != nil {
		return w, err
	}
	if w, err = basictl.StringRead(w, &item.CompressedData); err != nil {
		return w, err
	}
	if item.FieldsMask&(1<<5) != 0 {
		if w, err = basictl.IntRead(w, &item.Sharding); err != nil {
			return w, err
		}
	} else {
		item.Sharding = 0
	}
	return w, nil
}

// This method is general version of Write, use it instead!
func (item *StatshouseSendSourceBucket2) WriteGeneral(w []byte) (_ []byte, err error) {
	return item.Write(w), nil
}

func (item *StatshouseSendSourceBucket2) Write(w []byte) []byte {
	w = basictl.NatWrite(w, item.FieldsMask)
	w = item.Header.Write(w, item.FieldsMask)
	if item.FieldsMask&(1<<4) != 0 {
		w = basictl.StringWrite(w, item.Owner)
	}
	w = basictl.NatWrite(w, item.Time)
	w = basictl.StringWrite(w, item.BuildCommit)
	w = basictl.IntWrite(w, item.BuildCommitDate)
	w = basictl.NatWrite(w, item.BuildCommitTs)
	w = basictl.IntWrite(w, item.QueueSizeDisk)
	w = basictl.IntWrite(w, item.QueueSizeMemory)
	if item.FieldsMask&(1<<2) != 0 {
		w = basictl.IntWrite(w, item.QueueSizeDiskSum)
	}
	if item.FieldsMask&(1<<2) != 0 {
		w = basictl.IntWrite(w, item.QueueSizeMemorySum)
	}
	if item.FieldsMask&(1<<3) != 0 {
		w = basictl.IntWrite(w, item.QueueSizeDiskUnsent)
	}
	if item.FieldsMask&(1<<3) != 0 {
		w = basictl.IntWrite(w, item.QueueSizeDiskSumUnsent)
	}
	w = basictl.NatWrite(w, item.OriginalSize)
	w = basictl.StringWrite(w, item.CompressedData)
	if item.FieldsMask&(1<<5) != 0 {
		w = basictl.IntWrite(w, item.Sharding)
	}
	return w
}

func (item *StatshouseSendSourceBucket2) ReadBoxed(w []byte) (_ []byte, err error) {
	if w, err = basictl.NatReadExactTag(w, 0x44575940); err != nil {
		return w, err
	}
	return item.Read(w)
}

// This method is general version of WriteBoxed, use it instead!
func (item *StatshouseSendSourceBucket2) WriteBoxedGeneral(w []byte) (_ []byte, err error) {
	return item.WriteBoxed(w), nil
}

func (item *StatshouseSendSourceBucket2) WriteBoxed(w []byte) []byte {
	w = basictl.NatWrite(w, 0x44575940)
	return item.Write(w)
}

func (item *StatshouseSendSourceBucket2) ReadResult(w []byte, ret *string) (_ []byte, err error) {
	if w, err = basictl.NatReadExactTag(w, 0xb5286e24); err != nil {
		return w, err
	}
	return basictl.StringRead(w, ret)
}

func (item *StatshouseSendSourceBucket2) WriteResult(w []byte, ret string) (_ []byte, err error) {
	w = basictl.NatWrite(w, 0xb5286e24)
	w = basictl.StringWrite(w, ret)
	return w, nil
}

func (item *StatshouseSendSourceBucket2) ReadResultJSON(legacyTypeNames bool, in *basictl.JsonLexer, ret *string) error {
	if err := Json2ReadString(in, ret); err != nil {
		return err
	}
	return nil
}

func (item *StatshouseSendSourceBucket2) WriteResultJSON(w []byte, ret string) (_ []byte, err error) {
	return item.writeResultJSON(true, false, w, ret)
}

func (item *StatshouseSendSourceBucket2) writeResultJSON(newTypeNames bool, short bool, w []byte, ret string) (_ []byte, err error) {
	w = basictl.JSONWriteString(w, ret)
	return w, nil
}

func (item *StatshouseSendSourceBucket2) ReadResultWriteResultJSON(r []byte, w []byte) (_ []byte, _ []byte, err error) {
	var ret string
	if r, err = item.ReadResult(r, &ret); err != nil {
		return r, w, err
	}
	w, err = item.WriteResultJSON(w, ret)
	return r, w, err
}

func (item *StatshouseSendSourceBucket2) ReadResultWriteResultJSONOpt(newTypeNames bool, short bool, r []byte, w []byte) (_ []byte, _ []byte, err error) {
	var ret string
	if r, err = item.ReadResult(r, &ret); err != nil {
		return r, w, err
	}
	w, err = item.writeResultJSON(newTypeNames, short, w, ret)
	return r, w, err
}

func (item *StatshouseSendSourceBucket2) ReadResultJSONWriteResult(r []byte, w []byte) ([]byte, []byte, error) {
	var ret string
	err := item.ReadResultJSON(true, &basictl.JsonLexer{Data: r}, &ret)
	if err != nil {
		return r, w, err
	}
	w, err = item.WriteResult(w, ret)
	return r, w, err
}

func (item StatshouseSendSourceBucket2) String() string {
	return string(item.WriteJSON(nil))
}

func (item *StatshouseSendSourceBucket2) ReadJSON(legacyTypeNames bool, in *basictl.JsonLexer) error {
	var propFieldsMaskPresented bool
	var rawHeader []byte
	var propOwnerPresented bool
	var propTimePresented bool
	var trueTypeHistoricPresented bool
	var trueTypeHistoricValue bool
	var trueTypeSparePresented bool
	var trueTypeSpareValue bool
	var propBuildCommitPresented bool
	var propBuildCommitDatePresented bool
	var propBuildCommitTsPresented bool
	var propQueueSizeDiskPresented bool
	var propQueueSizeMemoryPresented bool
	var propQueueSizeDiskSumPresented bool
	var propQueueSizeMemorySumPresented bool
	var propQueueSizeDiskUnsentPresented bool
	var propQueueSizeDiskSumUnsentPresented bool
	var propOriginalSizePresented bool
	var propCompressedDataPresented bool
	var propShardingPresented bool

	if in != nil {
		in.Delim('{')
		if !in.Ok() {
			return in.Error()
		}
		for !in.IsDelim('}') {
			key := in.UnsafeFieldName(true)
			in.WantColon()
			switch key {
			case "fields_mask":
				if propFieldsMaskPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "fields_mask")
				}
				if err := Json2ReadUint32(in, &item.FieldsMask); err != nil {
					return err
				}
				propFieldsMaskPresented = true
			case "header":
				if rawHeader != nil {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "header")
				}
				rawHeader = in.Raw()
				if !in.Ok() {
					return in.Error()
				}
			case "owner":
				if propOwnerPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "owner")
				}
				if err := Json2ReadString(in, &item.Owner); err != nil {
					return err
				}
				propOwnerPresented = true
			case "time":
				if propTimePresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "time")
				}
				if err := Json2ReadUint32(in, &item.Time); err != nil {
					return err
				}
				propTimePresented = true
			case "historic":
				if trueTypeHistoricPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "historic")
				}
				if err := Json2ReadBool(in, &trueTypeHistoricValue); err != nil {
					return err
				}
				trueTypeHistoricPresented = true
			case "spare":
				if trueTypeSparePresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "spare")
				}
				if err := Json2ReadBool(in, &trueTypeSpareValue); err != nil {
					return err
				}
				trueTypeSparePresented = true
			case "build_commit":
				if propBuildCommitPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "build_commit")
				}
				if err := Json2ReadString(in, &item.BuildCommit); err != nil {
					return err
				}
				propBuildCommitPresented = true
			case "build_commit_date":
				if propBuildCommitDatePresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "build_commit_date")
				}
				if err := Json2ReadInt32(in, &item.BuildCommitDate); err != nil {
					return err
				}
				propBuildCommitDatePresented = true
			case "build_commit_ts":
				if propBuildCommitTsPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "build_commit_ts")
				}
				if err := Json2ReadUint32(in, &item.BuildCommitTs); err != nil {
					return err
				}
				propBuildCommitTsPresented = true
			case "queue_size_disk":
				if propQueueSizeDiskPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "queue_size_disk")
				}
				if err := Json2ReadInt32(in, &item.QueueSizeDisk); err != nil {
					return err
				}
				propQueueSizeDiskPresented = true
			case "queue_size_memory":
				if propQueueSizeMemoryPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "queue_size_memory")
				}
				if err := Json2ReadInt32(in, &item.QueueSizeMemory); err != nil {
					return err
				}
				propQueueSizeMemoryPresented = true
			case "queue_size_disk_sum":
				if propQueueSizeDiskSumPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "queue_size_disk_sum")
				}
				if err := Json2ReadInt32(in, &item.QueueSizeDiskSum); err != nil {
					return err
				}
				propQueueSizeDiskSumPresented = true
			case "queue_size_memory_sum":
				if propQueueSizeMemorySumPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "queue_size_memory_sum")
				}
				if err := Json2ReadInt32(in, &item.QueueSizeMemorySum); err != nil {
					return err
				}
				propQueueSizeMemorySumPresented = true
			case "queue_size_disk_unsent":
				if propQueueSizeDiskUnsentPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "queue_size_disk_unsent")
				}
				if err := Json2ReadInt32(in, &item.QueueSizeDiskUnsent); err != nil {
					return err
				}
				propQueueSizeDiskUnsentPresented = true
			case "queue_size_disk_sum_unsent":
				if propQueueSizeDiskSumUnsentPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "queue_size_disk_sum_unsent")
				}
				if err := Json2ReadInt32(in, &item.QueueSizeDiskSumUnsent); err != nil {
					return err
				}
				propQueueSizeDiskSumUnsentPresented = true
			case "original_size":
				if propOriginalSizePresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "original_size")
				}
				if err := Json2ReadUint32(in, &item.OriginalSize); err != nil {
					return err
				}
				propOriginalSizePresented = true
			case "compressed_data":
				if propCompressedDataPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "compressed_data")
				}
				if err := Json2ReadString(in, &item.CompressedData); err != nil {
					return err
				}
				propCompressedDataPresented = true
			case "sharding":
				if propShardingPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "sharding")
				}
				if err := Json2ReadInt32(in, &item.Sharding); err != nil {
					return err
				}
				propShardingPresented = true
			default:
				return ErrorInvalidJSONExcessElement("statshouse.sendSourceBucket2", key)
			}
			in.WantComma()
		}
		in.Delim('}')
		if !in.Ok() {
			return in.Error()
		}
	}
	if !propFieldsMaskPresented {
		item.FieldsMask = 0
	}
	if !propOwnerPresented {
		item.Owner = ""
	}
	if !propTimePresented {
		item.Time = 0
	}
	if !propBuildCommitPresented {
		item.BuildCommit = ""
	}
	if !propBuildCommitDatePresented {
		item.BuildCommitDate = 0
	}
	if !propBuildCommitTsPresented {
		item.BuildCommitTs = 0
	}
	if !propQueueSizeDiskPresented {
		item.QueueSizeDisk = 0
	}
	if !propQueueSizeMemoryPresented {
		item.QueueSizeMemory = 0
	}
	if !propQueueSizeDiskSumPresented {
		item.QueueSizeDiskSum = 0
	}
	if !propQueueSizeMemorySumPresented {
		item.QueueSizeMemorySum = 0
	}
	if !propQueueSizeDiskUnsentPresented {
		item.QueueSizeDiskUnsent = 0
	}
	if !propQueueSizeDiskSumUnsentPresented {
		item.QueueSizeDiskSumUnsent = 0
	}
	if !propOriginalSizePresented {
		item.OriginalSize = 0
	}
	if !propCompressedDataPresented {
		item.CompressedData = ""
	}
	if !propShardingPresented {
		item.Sharding = 0
	}
	if propOwnerPresented {
		item.FieldsMask |= 1 << 4
	}
	if trueTypeHistoricPresented {
		if trueTypeHistoricValue {
			item.FieldsMask |= 1 << 0
		}
	}
	if trueTypeSparePresented {
		if trueTypeSpareValue {
			item.FieldsMask |= 1 << 1
		}
	}
	if propQueueSizeDiskSumPresented {
		item.FieldsMask |= 1 << 2
	}
	if propQueueSizeMemorySumPresented {
		item.FieldsMask |= 1 << 2
	}
	if propQueueSizeDiskUnsentPresented {
		item.FieldsMask |= 1 << 3
	}
	if propQueueSizeDiskSumUnsentPresented {
		item.FieldsMask |= 1 << 3
	}
	if propShardingPresented {
		item.FieldsMask |= 1 << 5
	}
	var inHeaderPointer *basictl.JsonLexer
	inHeader := basictl.JsonLexer{Data: rawHeader}
	if rawHeader != nil {
		inHeaderPointer = &inHeader
	}
	if err := item.Header.ReadJSON(legacyTypeNames, inHeaderPointer, item.FieldsMask); err != nil {
		return err
	}

	// tries to set bit to zero if it is 1
	if trueTypeHistoricPresented && !trueTypeHistoricValue && (item.FieldsMask&(1<<0) != 0) {
		return ErrorInvalidJSON("statshouse.sendSourceBucket2", "fieldmask bit fields_mask.0 is indefinite because of the contradictions in values")
	}
	// tries to set bit to zero if it is 1
	if trueTypeSparePresented && !trueTypeSpareValue && (item.FieldsMask&(1<<1) != 0) {
		return ErrorInvalidJSON("statshouse.sendSourceBucket2", "fieldmask bit fields_mask.0 is indefinite because of the contradictions in values")
	}
	return nil
}

// This method is general version of WriteJSON, use it instead!
func (item *StatshouseSendSourceBucket2) WriteJSONGeneral(w []byte) (_ []byte, err error) {
	return item.WriteJSONOpt(true, false, w), nil
}

func (item *StatshouseSendSourceBucket2) WriteJSON(w []byte) []byte {
	return item.WriteJSONOpt(true, false, w)
}
func (item *StatshouseSendSourceBucket2) WriteJSONOpt(newTypeNames bool, short bool, w []byte) []byte {
	w = append(w, '{')
	backupIndexFieldsMask := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"fields_mask":`...)
	w = basictl.JSONWriteUint32(w, item.FieldsMask)
	if (item.FieldsMask != 0) == false {
		w = w[:backupIndexFieldsMask]
	}
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"header":`...)
	w = item.Header.WriteJSONOpt(newTypeNames, short, w, item.FieldsMask)
	if item.FieldsMask&(1<<4) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"owner":`...)
		w = basictl.JSONWriteString(w, item.Owner)
	}
	backupIndexTime := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"time":`...)
	w = basictl.JSONWriteUint32(w, item.Time)
	if (item.Time != 0) == false {
		w = w[:backupIndexTime]
	}
	if item.FieldsMask&(1<<0) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"historic":true`...)
	}
	if item.FieldsMask&(1<<1) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"spare":true`...)
	}
	backupIndexBuildCommit := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"build_commit":`...)
	w = basictl.JSONWriteString(w, item.BuildCommit)
	if (len(item.BuildCommit) != 0) == false {
		w = w[:backupIndexBuildCommit]
	}
	backupIndexBuildCommitDate := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"build_commit_date":`...)
	w = basictl.JSONWriteInt32(w, item.BuildCommitDate)
	if (item.BuildCommitDate != 0) == false {
		w = w[:backupIndexBuildCommitDate]
	}
	backupIndexBuildCommitTs := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"build_commit_ts":`...)
	w = basictl.JSONWriteUint32(w, item.BuildCommitTs)
	if (item.BuildCommitTs != 0) == false {
		w = w[:backupIndexBuildCommitTs]
	}
	backupIndexQueueSizeDisk := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"queue_size_disk":`...)
	w = basictl.JSONWriteInt32(w, item.QueueSizeDisk)
	if (item.QueueSizeDisk != 0) == false {
		w = w[:backupIndexQueueSizeDisk]
	}
	backupIndexQueueSizeMemory := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"queue_size_memory":`...)
	w = basictl.JSONWriteInt32(w, item.QueueSizeMemory)
	if (item.QueueSizeMemory != 0) == false {
		w = w[:backupIndexQueueSizeMemory]
	}
	if item.FieldsMask&(1<<2) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"queue_size_disk_sum":`...)
		w = basictl.JSONWriteInt32(w, item.QueueSizeDiskSum)
	}
	if item.FieldsMask&(1<<2) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"queue_size_memory_sum":`...)
		w = basictl.JSONWriteInt32(w, item.QueueSizeMemorySum)
	}
	if item.FieldsMask&(1<<3) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"queue_size_disk_unsent":`...)
		w = basictl.JSONWriteInt32(w, item.QueueSizeDiskUnsent)
	}
	if item.FieldsMask&(1<<3) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"queue_size_disk_sum_unsent":`...)
		w = basictl.JSONWriteInt32(w, item.QueueSizeDiskSumUnsent)
	}
	backupIndexOriginalSize := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"original_size":`...)
	w = basictl.JSONWriteUint32(w, item.OriginalSize)
	if (item.OriginalSize != 0) == false {
		w = w[:backupIndexOriginalSize]
	}
	backupIndexCompressedData := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"compressed_data":`...)
	w = basictl.JSONWriteString(w, item.CompressedData)
	if (len(item.CompressedData) != 0) == false {
		w = w[:backupIndexCompressedData]
	}
	if item.FieldsMask&(1<<5) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"sharding":`...)
		w = basictl.JSONWriteInt32(w, item.Sharding)
	}
	return append(w, '}')
}

func (item *StatshouseSendSourceBucket2) MarshalJSON() ([]byte, error) {
	return item.WriteJSON(nil), nil
}

func (item *StatshouseSendSourceBucket2) UnmarshalJSON(b []byte) error {
	if err := item.ReadJSON(true, &basictl.JsonLexer{Data: b}); err != nil {
		return ErrorInvalidJSON("statshouse.sendSourceBucket2", err.Error())
	}
	return nil
}

type StatshouseSendSourceBucket2Bytes struct {
	FieldsMask uint32
	Header     StatshouseCommonProxyHeaderBytes
	Owner      []byte // Conditional: item.FieldsMask.4
	Time       uint32
	// Historic (TrueType) // Conditional: item.FieldsMask.0
	// Spare (TrueType) // Conditional: item.FieldsMask.1
	BuildCommit            []byte
	BuildCommitDate        int32
	BuildCommitTs          uint32
	QueueSizeDisk          int32
	QueueSizeMemory        int32
	QueueSizeDiskSum       int32 // Conditional: item.FieldsMask.2
	QueueSizeMemorySum     int32 // Conditional: item.FieldsMask.2
	QueueSizeDiskUnsent    int32 // Conditional: item.FieldsMask.3
	QueueSizeDiskSumUnsent int32 // Conditional: item.FieldsMask.3
	OriginalSize           uint32
	CompressedData         []byte
	Sharding               int32 // Conditional: item.FieldsMask.5
}

func (StatshouseSendSourceBucket2Bytes) TLName() string { return "statshouse.sendSourceBucket2" }
func (StatshouseSendSourceBucket2Bytes) TLTag() uint32  { return 0x44575940 }

func (item *StatshouseSendSourceBucket2Bytes) SetOwner(v []byte) {
	item.Owner = v
	item.FieldsMask |= 1 << 4
}
func (item *StatshouseSendSourceBucket2Bytes) ClearOwner() {
	item.Owner = item.Owner[:0]
	item.FieldsMask &^= 1 << 4
}
func (item StatshouseSendSourceBucket2Bytes) IsSetOwner() bool { return item.FieldsMask&(1<<4) != 0 }

func (item *StatshouseSendSourceBucket2Bytes) SetHistoric(v bool) {
	if v {
		item.FieldsMask |= 1 << 0
	} else {
		item.FieldsMask &^= 1 << 0
	}
}
func (item StatshouseSendSourceBucket2Bytes) IsSetHistoric() bool { return item.FieldsMask&(1<<0) != 0 }

func (item *StatshouseSendSourceBucket2Bytes) SetSpare(v bool) {
	if v {
		item.FieldsMask |= 1 << 1
	} else {
		item.FieldsMask &^= 1 << 1
	}
}
func (item StatshouseSendSourceBucket2Bytes) IsSetSpare() bool { return item.FieldsMask&(1<<1) != 0 }

func (item *StatshouseSendSourceBucket2Bytes) SetQueueSizeDiskSum(v int32) {
	item.QueueSizeDiskSum = v
	item.FieldsMask |= 1 << 2
}
func (item *StatshouseSendSourceBucket2Bytes) ClearQueueSizeDiskSum() {
	item.QueueSizeDiskSum = 0
	item.FieldsMask &^= 1 << 2
}
func (item StatshouseSendSourceBucket2Bytes) IsSetQueueSizeDiskSum() bool {
	return item.FieldsMask&(1<<2) != 0
}

func (item *StatshouseSendSourceBucket2Bytes) SetQueueSizeMemorySum(v int32) {
	item.QueueSizeMemorySum = v
	item.FieldsMask |= 1 << 2
}
func (item *StatshouseSendSourceBucket2Bytes) ClearQueueSizeMemorySum() {
	item.QueueSizeMemorySum = 0
	item.FieldsMask &^= 1 << 2
}
func (item StatshouseSendSourceBucket2Bytes) IsSetQueueSizeMemorySum() bool {
	return item.FieldsMask&(1<<2) != 0
}

func (item *StatshouseSendSourceBucket2Bytes) SetQueueSizeDiskUnsent(v int32) {
	item.QueueSizeDiskUnsent = v
	item.FieldsMask |= 1 << 3
}
func (item *StatshouseSendSourceBucket2Bytes) ClearQueueSizeDiskUnsent() {
	item.QueueSizeDiskUnsent = 0
	item.FieldsMask &^= 1 << 3
}
func (item StatshouseSendSourceBucket2Bytes) IsSetQueueSizeDiskUnsent() bool {
	return item.FieldsMask&(1<<3) != 0
}

func (item *StatshouseSendSourceBucket2Bytes) SetQueueSizeDiskSumUnsent(v int32) {
	item.QueueSizeDiskSumUnsent = v
	item.FieldsMask |= 1 << 3
}
func (item *StatshouseSendSourceBucket2Bytes) ClearQueueSizeDiskSumUnsent() {
	item.QueueSizeDiskSumUnsent = 0
	item.FieldsMask &^= 1 << 3
}
func (item StatshouseSendSourceBucket2Bytes) IsSetQueueSizeDiskSumUnsent() bool {
	return item.FieldsMask&(1<<3) != 0
}

func (item *StatshouseSendSourceBucket2Bytes) SetSharding(v int32) {
	item.Sharding = v
	item.FieldsMask |= 1 << 5
}
func (item *StatshouseSendSourceBucket2Bytes) ClearSharding() {
	item.Sharding = 0
	item.FieldsMask &^= 1 << 5
}
func (item StatshouseSendSourceBucket2Bytes) IsSetSharding() bool { return item.FieldsMask&(1<<5) != 0 }

func (item *StatshouseSendSourceBucket2Bytes) Reset() {
	item.FieldsMask = 0
	item.Header.Reset()
	item.Owner = item.Owner[:0]
	item.Time = 0
	item.BuildCommit = item.BuildCommit[:0]
	item.BuildCommitDate = 0
	item.BuildCommitTs = 0
	item.QueueSizeDisk = 0
	item.QueueSizeMemory = 0
	item.QueueSizeDiskSum = 0
	item.QueueSizeMemorySum = 0
	item.QueueSizeDiskUnsent = 0
	item.QueueSizeDiskSumUnsent = 0
	item.OriginalSize = 0
	item.CompressedData = item.CompressedData[:0]
	item.Sharding = 0
}

func (item *StatshouseSendSourceBucket2Bytes) Read(w []byte) (_ []byte, err error) {
	if w, err = basictl.NatRead(w, &item.FieldsMask); err != nil {
		return w, err
	}
	if w, err = item.Header.Read(w, item.FieldsMask); err != nil {
		return w, err
	}
	if item.FieldsMask&(1<<4) != 0 {
		if w, err = basictl.StringReadBytes(w, &item.Owner); err != nil {
			return w, err
		}
	} else {
		item.Owner = item.Owner[:0]
	}
	if w, err = basictl.NatRead(w, &item.Time); err != nil {
		return w, err
	}
	if w, err = basictl.StringReadBytes(w, &item.BuildCommit); err != nil {
		return w, err
	}
	if w, err = basictl.IntRead(w, &item.BuildCommitDate); err != nil {
		return w, err
	}
	if w, err = basictl.NatRead(w, &item.BuildCommitTs); err != nil {
		return w, err
	}
	if w, err = basictl.IntRead(w, &item.QueueSizeDisk); err != nil {
		return w, err
	}
	if w, err = basictl.IntRead(w, &item.QueueSizeMemory); err != nil {
		return w, err
	}
	if item.FieldsMask&(1<<2) != 0 {
		if w, err = basictl.IntRead(w, &item.QueueSizeDiskSum); err != nil {
			return w, err
		}
	} else {
		item.QueueSizeDiskSum = 0
	}
	if item.FieldsMask&(1<<2) != 0 {
		if w, err = basictl.IntRead(w, &item.QueueSizeMemorySum); err != nil {
			return w, err
		}
	} else {
		item.QueueSizeMemorySum = 0
	}
	if item.FieldsMask&(1<<3) != 0 {
		if w, err = basictl.IntRead(w, &item.QueueSizeDiskUnsent); err != nil {
			return w, err
		}
	} else {
		item.QueueSizeDiskUnsent = 0
	}
	if item.FieldsMask&(1<<3) != 0 {
		if w, err = basictl.IntRead(w, &item.QueueSizeDiskSumUnsent); err != nil {
			return w, err
		}
	} else {
		item.QueueSizeDiskSumUnsent = 0
	}
	if w, err = basictl.NatRead(w, &item.OriginalSize); err != nil {
		return w, err
	}
	if w, err = basictl.StringReadBytes(w, &item.CompressedData); err != nil {
		return w, err
	}
	if item.FieldsMask&(1<<5) != 0 {
		if w, err = basictl.IntRead(w, &item.Sharding); err != nil {
			return w, err
		}
	} else {
		item.Sharding = 0
	}
	return w, nil
}

// This method is general version of Write, use it instead!
func (item *StatshouseSendSourceBucket2Bytes) WriteGeneral(w []byte) (_ []byte, err error) {
	return item.Write(w), nil
}

func (item *StatshouseSendSourceBucket2Bytes) Write(w []byte) []byte {
	w = basictl.NatWrite(w, item.FieldsMask)
	w = item.Header.Write(w, item.FieldsMask)
	if item.FieldsMask&(1<<4) != 0 {
		w = basictl.StringWriteBytes(w, item.Owner)
	}
	w = basictl.NatWrite(w, item.Time)
	w = basictl.StringWriteBytes(w, item.BuildCommit)
	w = basictl.IntWrite(w, item.BuildCommitDate)
	w = basictl.NatWrite(w, item.BuildCommitTs)
	w = basictl.IntWrite(w, item.QueueSizeDisk)
	w = basictl.IntWrite(w, item.QueueSizeMemory)
	if item.FieldsMask&(1<<2) != 0 {
		w = basictl.IntWrite(w, item.QueueSizeDiskSum)
	}
	if item.FieldsMask&(1<<2) != 0 {
		w = basictl.IntWrite(w, item.QueueSizeMemorySum)
	}
	if item.FieldsMask&(1<<3) != 0 {
		w = basictl.IntWrite(w, item.QueueSizeDiskUnsent)
	}
	if item.FieldsMask&(1<<3) != 0 {
		w = basictl.IntWrite(w, item.QueueSizeDiskSumUnsent)
	}
	w = basictl.NatWrite(w, item.OriginalSize)
	w = basictl.StringWriteBytes(w, item.CompressedData)
	if item.FieldsMask&(1<<5) != 0 {
		w = basictl.IntWrite(w, item.Sharding)
	}
	return w
}

func (item *StatshouseSendSourceBucket2Bytes) ReadBoxed(w []byte) (_ []byte, err error) {
	if w, err = basictl.NatReadExactTag(w, 0x44575940); err != nil {
		return w, err
	}
	return item.Read(w)
}

// This method is general version of WriteBoxed, use it instead!
func (item *StatshouseSendSourceBucket2Bytes) WriteBoxedGeneral(w []byte) (_ []byte, err error) {
	return item.WriteBoxed(w), nil
}

func (item *StatshouseSendSourceBucket2Bytes) WriteBoxed(w []byte) []byte {
	w = basictl.NatWrite(w, 0x44575940)
	return item.Write(w)
}

func (item *StatshouseSendSourceBucket2Bytes) ReadResult(w []byte, ret *[]byte) (_ []byte, err error) {
	if w, err = basictl.NatReadExactTag(w, 0xb5286e24); err != nil {
		return w, err
	}
	return basictl.StringReadBytes(w, ret)
}

func (item *StatshouseSendSourceBucket2Bytes) WriteResult(w []byte, ret []byte) (_ []byte, err error) {
	w = basictl.NatWrite(w, 0xb5286e24)
	w = basictl.StringWriteBytes(w, ret)
	return w, nil
}

func (item *StatshouseSendSourceBucket2Bytes) ReadResultJSON(legacyTypeNames bool, in *basictl.JsonLexer, ret *[]byte) error {
	if err := Json2ReadStringBytes(in, ret); err != nil {
		return err
	}
	return nil
}

func (item *StatshouseSendSourceBucket2Bytes) WriteResultJSON(w []byte, ret []byte) (_ []byte, err error) {
	return item.writeResultJSON(true, false, w, ret)
}

func (item *StatshouseSendSourceBucket2Bytes) writeResultJSON(newTypeNames bool, short bool, w []byte, ret []byte) (_ []byte, err error) {
	w = basictl.JSONWriteStringBytes(w, ret)
	return w, nil
}

func (item *StatshouseSendSourceBucket2Bytes) ReadResultWriteResultJSON(r []byte, w []byte) (_ []byte, _ []byte, err error) {
	var ret []byte
	if r, err = item.ReadResult(r, &ret); err != nil {
		return r, w, err
	}
	w, err = item.WriteResultJSON(w, ret)
	return r, w, err
}

func (item *StatshouseSendSourceBucket2Bytes) ReadResultWriteResultJSONOpt(newTypeNames bool, short bool, r []byte, w []byte) (_ []byte, _ []byte, err error) {
	var ret []byte
	if r, err = item.ReadResult(r, &ret); err != nil {
		return r, w, err
	}
	w, err = item.writeResultJSON(newTypeNames, short, w, ret)
	return r, w, err
}

func (item *StatshouseSendSourceBucket2Bytes) ReadResultJSONWriteResult(r []byte, w []byte) ([]byte, []byte, error) {
	var ret []byte
	err := item.ReadResultJSON(true, &basictl.JsonLexer{Data: r}, &ret)
	if err != nil {
		return r, w, err
	}
	w, err = item.WriteResult(w, ret)
	return r, w, err
}

func (item StatshouseSendSourceBucket2Bytes) String() string {
	return string(item.WriteJSON(nil))
}

func (item *StatshouseSendSourceBucket2Bytes) ReadJSON(legacyTypeNames bool, in *basictl.JsonLexer) error {
	var propFieldsMaskPresented bool
	var rawHeader []byte
	var propOwnerPresented bool
	var propTimePresented bool
	var trueTypeHistoricPresented bool
	var trueTypeHistoricValue bool
	var trueTypeSparePresented bool
	var trueTypeSpareValue bool
	var propBuildCommitPresented bool
	var propBuildCommitDatePresented bool
	var propBuildCommitTsPresented bool
	var propQueueSizeDiskPresented bool
	var propQueueSizeMemoryPresented bool
	var propQueueSizeDiskSumPresented bool
	var propQueueSizeMemorySumPresented bool
	var propQueueSizeDiskUnsentPresented bool
	var propQueueSizeDiskSumUnsentPresented bool
	var propOriginalSizePresented bool
	var propCompressedDataPresented bool
	var propShardingPresented bool

	if in != nil {
		in.Delim('{')
		if !in.Ok() {
			return in.Error()
		}
		for !in.IsDelim('}') {
			key := in.UnsafeFieldName(true)
			in.WantColon()
			switch key {
			case "fields_mask":
				if propFieldsMaskPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "fields_mask")
				}
				if err := Json2ReadUint32(in, &item.FieldsMask); err != nil {
					return err
				}
				propFieldsMaskPresented = true
			case "header":
				if rawHeader != nil {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "header")
				}
				rawHeader = in.Raw()
				if !in.Ok() {
					return in.Error()
				}
			case "owner":
				if propOwnerPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "owner")
				}
				if err := Json2ReadStringBytes(in, &item.Owner); err != nil {
					return err
				}
				propOwnerPresented = true
			case "time":
				if propTimePresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "time")
				}
				if err := Json2ReadUint32(in, &item.Time); err != nil {
					return err
				}
				propTimePresented = true
			case "historic":
				if trueTypeHistoricPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "historic")
				}
				if err := Json2ReadBool(in, &trueTypeHistoricValue); err != nil {
					return err
				}
				trueTypeHistoricPresented = true
			case "spare":
				if trueTypeSparePresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "spare")
				}
				if err := Json2ReadBool(in, &trueTypeSpareValue); err != nil {
					return err
				}
				trueTypeSparePresented = true
			case "build_commit":
				if propBuildCommitPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "build_commit")
				}
				if err := Json2ReadStringBytes(in, &item.BuildCommit); err != nil {
					return err
				}
				propBuildCommitPresented = true
			case "build_commit_date":
				if propBuildCommitDatePresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "build_commit_date")
				}
				if err := Json2ReadInt32(in, &item.BuildCommitDate); err != nil {
					return err
				}
				propBuildCommitDatePresented = true
			case "build_commit_ts":
				if propBuildCommitTsPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "build_commit_ts")
				}
				if err := Json2ReadUint32(in, &item.BuildCommitTs); err != nil {
					return err
				}
				propBuildCommitTsPresented = true
			case "queue_size_disk":
				if propQueueSizeDiskPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "queue_size_disk")
				}
				if err := Json2ReadInt32(in, &item.QueueSizeDisk); err != nil {
					return err
				}
				propQueueSizeDiskPresented = true
			case "queue_size_memory":
				if propQueueSizeMemoryPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "queue_size_memory")
				}
				if err := Json2ReadInt32(in, &item.QueueSizeMemory); err != nil {
					return err
				}
				propQueueSizeMemoryPresented = true
			case "queue_size_disk_sum":
				if propQueueSizeDiskSumPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "queue_size_disk_sum")
				}
				if err := Json2ReadInt32(in, &item.QueueSizeDiskSum); err != nil {
					return err
				}
				propQueueSizeDiskSumPresented = true
			case "queue_size_memory_sum":
				if propQueueSizeMemorySumPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "queue_size_memory_sum")
				}
				if err := Json2ReadInt32(in, &item.QueueSizeMemorySum); err != nil {
					return err
				}
				propQueueSizeMemorySumPresented = true
			case "queue_size_disk_unsent":
				if propQueueSizeDiskUnsentPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "queue_size_disk_unsent")
				}
				if err := Json2ReadInt32(in, &item.QueueSizeDiskUnsent); err != nil {
					return err
				}
				propQueueSizeDiskUnsentPresented = true
			case "queue_size_disk_sum_unsent":
				if propQueueSizeDiskSumUnsentPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "queue_size_disk_sum_unsent")
				}
				if err := Json2ReadInt32(in, &item.QueueSizeDiskSumUnsent); err != nil {
					return err
				}
				propQueueSizeDiskSumUnsentPresented = true
			case "original_size":
				if propOriginalSizePresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "original_size")
				}
				if err := Json2ReadUint32(in, &item.OriginalSize); err != nil {
					return err
				}
				propOriginalSizePresented = true
			case "compressed_data":
				if propCompressedDataPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "compressed_data")
				}
				if err := Json2ReadStringBytes(in, &item.CompressedData); err != nil {
					return err
				}
				propCompressedDataPresented = true
			case "sharding":
				if propShardingPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket2", "sharding")
				}
				if err := Json2ReadInt32(in, &item.Sharding); err != nil {
					return err
				}
				propShardingPresented = true
			default:
				return ErrorInvalidJSONExcessElement("statshouse.sendSourceBucket2", key)
			}
			in.WantComma()
		}
		in.Delim('}')
		if !in.Ok() {
			return in.Error()
		}
	}
	if !propFieldsMaskPresented {
		item.FieldsMask = 0
	}
	if !propOwnerPresented {
		item.Owner = item.Owner[:0]
	}
	if !propTimePresented {
		item.Time = 0
	}
	if !propBuildCommitPresented {
		item.BuildCommit = item.BuildCommit[:0]
	}
	if !propBuildCommitDatePresented {
		item.BuildCommitDate = 0
	}
	if !propBuildCommitTsPresented {
		item.BuildCommitTs = 0
	}
	if !propQueueSizeDiskPresented {
		item.QueueSizeDisk = 0
	}
	if !propQueueSizeMemoryPresented {
		item.QueueSizeMemory = 0
	}
	if !propQueueSizeDiskSumPresented {
		item.QueueSizeDiskSum = 0
	}
	if !propQueueSizeMemorySumPresented {
		item.QueueSizeMemorySum = 0
	}
	if !propQueueSizeDiskUnsentPresented {
		item.QueueSizeDiskUnsent = 0
	}
	if !propQueueSizeDiskSumUnsentPresented {
		item.QueueSizeDiskSumUnsent = 0
	}
	if !propOriginalSizePresented {
		item.OriginalSize = 0
	}
	if !propCompressedDataPresented {
		item.CompressedData = item.CompressedData[:0]
	}
	if !propShardingPresented {
		item.Sharding = 0
	}
	if propOwnerPresented {
		item.FieldsMask |= 1 << 4
	}
	if trueTypeHistoricPresented {
		if trueTypeHistoricValue {
			item.FieldsMask |= 1 << 0
		}
	}
	if trueTypeSparePresented {
		if trueTypeSpareValue {
			item.FieldsMask |= 1 << 1
		}
	}
	if propQueueSizeDiskSumPresented {
		item.FieldsMask |= 1 << 2
	}
	if propQueueSizeMemorySumPresented {
		item.FieldsMask |= 1 << 2
	}
	if propQueueSizeDiskUnsentPresented {
		item.FieldsMask |= 1 << 3
	}
	if propQueueSizeDiskSumUnsentPresented {
		item.FieldsMask |= 1 << 3
	}
	if propShardingPresented {
		item.FieldsMask |= 1 << 5
	}
	var inHeaderPointer *basictl.JsonLexer
	inHeader := basictl.JsonLexer{Data: rawHeader}
	if rawHeader != nil {
		inHeaderPointer = &inHeader
	}
	if err := item.Header.ReadJSON(legacyTypeNames, inHeaderPointer, item.FieldsMask); err != nil {
		return err
	}

	// tries to set bit to zero if it is 1
	if trueTypeHistoricPresented && !trueTypeHistoricValue && (item.FieldsMask&(1<<0) != 0) {
		return ErrorInvalidJSON("statshouse.sendSourceBucket2", "fieldmask bit fields_mask.0 is indefinite because of the contradictions in values")
	}
	// tries to set bit to zero if it is 1
	if trueTypeSparePresented && !trueTypeSpareValue && (item.FieldsMask&(1<<1) != 0) {
		return ErrorInvalidJSON("statshouse.sendSourceBucket2", "fieldmask bit fields_mask.0 is indefinite because of the contradictions in values")
	}
	return nil
}

// This method is general version of WriteJSON, use it instead!
func (item *StatshouseSendSourceBucket2Bytes) WriteJSONGeneral(w []byte) (_ []byte, err error) {
	return item.WriteJSONOpt(true, false, w), nil
}

func (item *StatshouseSendSourceBucket2Bytes) WriteJSON(w []byte) []byte {
	return item.WriteJSONOpt(true, false, w)
}
func (item *StatshouseSendSourceBucket2Bytes) WriteJSONOpt(newTypeNames bool, short bool, w []byte) []byte {
	w = append(w, '{')
	backupIndexFieldsMask := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"fields_mask":`...)
	w = basictl.JSONWriteUint32(w, item.FieldsMask)
	if (item.FieldsMask != 0) == false {
		w = w[:backupIndexFieldsMask]
	}
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"header":`...)
	w = item.Header.WriteJSONOpt(newTypeNames, short, w, item.FieldsMask)
	if item.FieldsMask&(1<<4) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"owner":`...)
		w = basictl.JSONWriteStringBytes(w, item.Owner)
	}
	backupIndexTime := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"time":`...)
	w = basictl.JSONWriteUint32(w, item.Time)
	if (item.Time != 0) == false {
		w = w[:backupIndexTime]
	}
	if item.FieldsMask&(1<<0) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"historic":true`...)
	}
	if item.FieldsMask&(1<<1) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"spare":true`...)
	}
	backupIndexBuildCommit := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"build_commit":`...)
	w = basictl.JSONWriteStringBytes(w, item.BuildCommit)
	if (len(item.BuildCommit) != 0) == false {
		w = w[:backupIndexBuildCommit]
	}
	backupIndexBuildCommitDate := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"build_commit_date":`...)
	w = basictl.JSONWriteInt32(w, item.BuildCommitDate)
	if (item.BuildCommitDate != 0) == false {
		w = w[:backupIndexBuildCommitDate]
	}
	backupIndexBuildCommitTs := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"build_commit_ts":`...)
	w = basictl.JSONWriteUint32(w, item.BuildCommitTs)
	if (item.BuildCommitTs != 0) == false {
		w = w[:backupIndexBuildCommitTs]
	}
	backupIndexQueueSizeDisk := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"queue_size_disk":`...)
	w = basictl.JSONWriteInt32(w, item.QueueSizeDisk)
	if (item.QueueSizeDisk != 0) == false {
		w = w[:backupIndexQueueSizeDisk]
	}
	backupIndexQueueSizeMemory := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"queue_size_memory":`...)
	w = basictl.JSONWriteInt32(w, item.QueueSizeMemory)
	if (item.QueueSizeMemory != 0) == false {
		w = w[:backupIndexQueueSizeMemory]
	}
	if item.FieldsMask&(1<<2) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"queue_size_disk_sum":`...)
		w = basictl.JSONWriteInt32(w, item.QueueSizeDiskSum)
	}
	if item.FieldsMask&(1<<2) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"queue_size_memory_sum":`...)
		w = basictl.JSONWriteInt32(w, item.QueueSizeMemorySum)
	}
	if item.FieldsMask&(1<<3) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"queue_size_disk_unsent":`...)
		w = basictl.JSONWriteInt32(w, item.QueueSizeDiskUnsent)
	}
	if item.FieldsMask&(1<<3) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"queue_size_disk_sum_unsent":`...)
		w = basictl.JSONWriteInt32(w, item.QueueSizeDiskSumUnsent)
	}
	backupIndexOriginalSize := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"original_size":`...)
	w = basictl.JSONWriteUint32(w, item.OriginalSize)
	if (item.OriginalSize != 0) == false {
		w = w[:backupIndexOriginalSize]
	}
	backupIndexCompressedData := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"compressed_data":`...)
	w = basictl.JSONWriteStringBytes(w, item.CompressedData)
	if (len(item.CompressedData) != 0) == false {
		w = w[:backupIndexCompressedData]
	}
	if item.FieldsMask&(1<<5) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"sharding":`...)
		w = basictl.JSONWriteInt32(w, item.Sharding)
	}
	return append(w, '}')
}

func (item *StatshouseSendSourceBucket2Bytes) MarshalJSON() ([]byte, error) {
	return item.WriteJSON(nil), nil
}

func (item *StatshouseSendSourceBucket2Bytes) UnmarshalJSON(b []byte) error {
	if err := item.ReadJSON(true, &basictl.JsonLexer{Data: b}); err != nil {
		return ErrorInvalidJSON("statshouse.sendSourceBucket2", err.Error())
	}
	return nil
}
