// Copyright 2023 V Kontakte LLC
//
// This Source Code Form is subject to the terms of the Mozilla Public
// License, v. 2.0. If a copy of the MPL was not distributed with this
// file, You can obtain one at https://mozilla.org/MPL/2.0/.

// Code generated by vktl/cmd/tlgen2; DO NOT EDIT.
package internal

import (
	"github.com/vkcom/statshouse/internal/vkgo/basictl"
)

var _ = basictl.NatWrite

type StatshouseSendSourceBucket3 struct {
	FieldsMask uint32
	Header     StatshouseCommonProxyHeader
	Time       uint32
	// Historic (TrueType) // Conditional: item.FieldsMask.0
	// Spare (TrueType) // Conditional: item.FieldsMask.1
	BuildCommit            string
	BuildCommitDate        int32
	BuildCommitTs          int32
	QueueSizeDisk          int32
	QueueSizeMemory        int32
	QueueSizeDiskSum       int32 // Conditional: item.FieldsMask.2
	QueueSizeMemorySum     int32 // Conditional: item.FieldsMask.2
	QueueSizeDiskUnsent    int32 // Conditional: item.FieldsMask.3
	QueueSizeDiskSumUnsent int32 // Conditional: item.FieldsMask.3
	OriginalSize           uint32
	CompressedData         string
}

func (StatshouseSendSourceBucket3) TLName() string { return "statshouse.sendSourceBucket3" }
func (StatshouseSendSourceBucket3) TLTag() uint32  { return 0x0d04aa3f }

func (item *StatshouseSendSourceBucket3) SetHistoric(v bool) {
	if v {
		item.FieldsMask |= 1 << 0
	} else {
		item.FieldsMask &^= 1 << 0
	}
}
func (item StatshouseSendSourceBucket3) IsSetHistoric() bool { return item.FieldsMask&(1<<0) != 0 }

func (item *StatshouseSendSourceBucket3) SetSpare(v bool) {
	if v {
		item.FieldsMask |= 1 << 1
	} else {
		item.FieldsMask &^= 1 << 1
	}
}
func (item StatshouseSendSourceBucket3) IsSetSpare() bool { return item.FieldsMask&(1<<1) != 0 }

func (item *StatshouseSendSourceBucket3) SetQueueSizeDiskSum(v int32) {
	item.QueueSizeDiskSum = v
	item.FieldsMask |= 1 << 2
}
func (item *StatshouseSendSourceBucket3) ClearQueueSizeDiskSum() {
	item.QueueSizeDiskSum = 0
	item.FieldsMask &^= 1 << 2
}
func (item StatshouseSendSourceBucket3) IsSetQueueSizeDiskSum() bool {
	return item.FieldsMask&(1<<2) != 0
}

func (item *StatshouseSendSourceBucket3) SetQueueSizeMemorySum(v int32) {
	item.QueueSizeMemorySum = v
	item.FieldsMask |= 1 << 2
}
func (item *StatshouseSendSourceBucket3) ClearQueueSizeMemorySum() {
	item.QueueSizeMemorySum = 0
	item.FieldsMask &^= 1 << 2
}
func (item StatshouseSendSourceBucket3) IsSetQueueSizeMemorySum() bool {
	return item.FieldsMask&(1<<2) != 0
}

func (item *StatshouseSendSourceBucket3) SetQueueSizeDiskUnsent(v int32) {
	item.QueueSizeDiskUnsent = v
	item.FieldsMask |= 1 << 3
}
func (item *StatshouseSendSourceBucket3) ClearQueueSizeDiskUnsent() {
	item.QueueSizeDiskUnsent = 0
	item.FieldsMask &^= 1 << 3
}
func (item StatshouseSendSourceBucket3) IsSetQueueSizeDiskUnsent() bool {
	return item.FieldsMask&(1<<3) != 0
}

func (item *StatshouseSendSourceBucket3) SetQueueSizeDiskSumUnsent(v int32) {
	item.QueueSizeDiskSumUnsent = v
	item.FieldsMask |= 1 << 3
}
func (item *StatshouseSendSourceBucket3) ClearQueueSizeDiskSumUnsent() {
	item.QueueSizeDiskSumUnsent = 0
	item.FieldsMask &^= 1 << 3
}
func (item StatshouseSendSourceBucket3) IsSetQueueSizeDiskSumUnsent() bool {
	return item.FieldsMask&(1<<3) != 0
}

func (item *StatshouseSendSourceBucket3) Reset() {
	item.FieldsMask = 0
	item.Header.Reset()
	item.Time = 0
	item.BuildCommit = ""
	item.BuildCommitDate = 0
	item.BuildCommitTs = 0
	item.QueueSizeDisk = 0
	item.QueueSizeMemory = 0
	item.QueueSizeDiskSum = 0
	item.QueueSizeMemorySum = 0
	item.QueueSizeDiskUnsent = 0
	item.QueueSizeDiskSumUnsent = 0
	item.OriginalSize = 0
	item.CompressedData = ""
}

func (item *StatshouseSendSourceBucket3) Read(w []byte) (_ []byte, err error) {
	if w, err = basictl.NatRead(w, &item.FieldsMask); err != nil {
		return w, err
	}
	if w, err = item.Header.Read(w, item.FieldsMask); err != nil {
		return w, err
	}
	if w, err = basictl.NatRead(w, &item.Time); err != nil {
		return w, err
	}
	if w, err = basictl.StringRead(w, &item.BuildCommit); err != nil {
		return w, err
	}
	if w, err = basictl.IntRead(w, &item.BuildCommitDate); err != nil {
		return w, err
	}
	if w, err = basictl.IntRead(w, &item.BuildCommitTs); err != nil {
		return w, err
	}
	if w, err = basictl.IntRead(w, &item.QueueSizeDisk); err != nil {
		return w, err
	}
	if w, err = basictl.IntRead(w, &item.QueueSizeMemory); err != nil {
		return w, err
	}
	if item.FieldsMask&(1<<2) != 0 {
		if w, err = basictl.IntRead(w, &item.QueueSizeDiskSum); err != nil {
			return w, err
		}
	} else {
		item.QueueSizeDiskSum = 0
	}
	if item.FieldsMask&(1<<2) != 0 {
		if w, err = basictl.IntRead(w, &item.QueueSizeMemorySum); err != nil {
			return w, err
		}
	} else {
		item.QueueSizeMemorySum = 0
	}
	if item.FieldsMask&(1<<3) != 0 {
		if w, err = basictl.IntRead(w, &item.QueueSizeDiskUnsent); err != nil {
			return w, err
		}
	} else {
		item.QueueSizeDiskUnsent = 0
	}
	if item.FieldsMask&(1<<3) != 0 {
		if w, err = basictl.IntRead(w, &item.QueueSizeDiskSumUnsent); err != nil {
			return w, err
		}
	} else {
		item.QueueSizeDiskSumUnsent = 0
	}
	if w, err = basictl.NatRead(w, &item.OriginalSize); err != nil {
		return w, err
	}
	return basictl.StringRead(w, &item.CompressedData)
}

// This method is general version of Write, use it instead!
func (item *StatshouseSendSourceBucket3) WriteGeneral(w []byte) (_ []byte, err error) {
	return item.Write(w), nil
}

func (item *StatshouseSendSourceBucket3) Write(w []byte) []byte {
	w = basictl.NatWrite(w, item.FieldsMask)
	w = item.Header.Write(w, item.FieldsMask)
	w = basictl.NatWrite(w, item.Time)
	w = basictl.StringWrite(w, item.BuildCommit)
	w = basictl.IntWrite(w, item.BuildCommitDate)
	w = basictl.IntWrite(w, item.BuildCommitTs)
	w = basictl.IntWrite(w, item.QueueSizeDisk)
	w = basictl.IntWrite(w, item.QueueSizeMemory)
	if item.FieldsMask&(1<<2) != 0 {
		w = basictl.IntWrite(w, item.QueueSizeDiskSum)
	}
	if item.FieldsMask&(1<<2) != 0 {
		w = basictl.IntWrite(w, item.QueueSizeMemorySum)
	}
	if item.FieldsMask&(1<<3) != 0 {
		w = basictl.IntWrite(w, item.QueueSizeDiskUnsent)
	}
	if item.FieldsMask&(1<<3) != 0 {
		w = basictl.IntWrite(w, item.QueueSizeDiskSumUnsent)
	}
	w = basictl.NatWrite(w, item.OriginalSize)
	w = basictl.StringWrite(w, item.CompressedData)
	return w
}

func (item *StatshouseSendSourceBucket3) ReadBoxed(w []byte) (_ []byte, err error) {
	if w, err = basictl.NatReadExactTag(w, 0x0d04aa3f); err != nil {
		return w, err
	}
	return item.Read(w)
}

// This method is general version of WriteBoxed, use it instead!
func (item *StatshouseSendSourceBucket3) WriteBoxedGeneral(w []byte) (_ []byte, err error) {
	return item.WriteBoxed(w), nil
}

func (item *StatshouseSendSourceBucket3) WriteBoxed(w []byte) []byte {
	w = basictl.NatWrite(w, 0x0d04aa3f)
	return item.Write(w)
}

func (item *StatshouseSendSourceBucket3) ReadResult(w []byte, ret *StatshouseSendSourceBucket3Response) (_ []byte, err error) {
	return ret.ReadBoxed(w)
}

func (item *StatshouseSendSourceBucket3) WriteResult(w []byte, ret StatshouseSendSourceBucket3Response) (_ []byte, err error) {
	w = ret.WriteBoxed(w)
	return w, nil
}

func (item *StatshouseSendSourceBucket3) ReadResultJSON(legacyTypeNames bool, in *basictl.JsonLexer, ret *StatshouseSendSourceBucket3Response) error {
	if err := ret.ReadJSON(legacyTypeNames, in); err != nil {
		return err
	}
	return nil
}

func (item *StatshouseSendSourceBucket3) WriteResultJSON(w []byte, ret StatshouseSendSourceBucket3Response) (_ []byte, err error) {
	return item.writeResultJSON(true, false, w, ret)
}

func (item *StatshouseSendSourceBucket3) writeResultJSON(newTypeNames bool, short bool, w []byte, ret StatshouseSendSourceBucket3Response) (_ []byte, err error) {
	w = ret.WriteJSONOpt(newTypeNames, short, w)
	return w, nil
}

func (item *StatshouseSendSourceBucket3) ReadResultWriteResultJSON(r []byte, w []byte) (_ []byte, _ []byte, err error) {
	var ret StatshouseSendSourceBucket3Response
	if r, err = item.ReadResult(r, &ret); err != nil {
		return r, w, err
	}
	w, err = item.WriteResultJSON(w, ret)
	return r, w, err
}

func (item *StatshouseSendSourceBucket3) ReadResultWriteResultJSONOpt(newTypeNames bool, short bool, r []byte, w []byte) (_ []byte, _ []byte, err error) {
	var ret StatshouseSendSourceBucket3Response
	if r, err = item.ReadResult(r, &ret); err != nil {
		return r, w, err
	}
	w, err = item.writeResultJSON(newTypeNames, short, w, ret)
	return r, w, err
}

func (item *StatshouseSendSourceBucket3) ReadResultJSONWriteResult(r []byte, w []byte) ([]byte, []byte, error) {
	var ret StatshouseSendSourceBucket3Response
	err := item.ReadResultJSON(true, &basictl.JsonLexer{Data: r}, &ret)
	if err != nil {
		return r, w, err
	}
	w, err = item.WriteResult(w, ret)
	return r, w, err
}

func (item StatshouseSendSourceBucket3) String() string {
	return string(item.WriteJSON(nil))
}

func (item *StatshouseSendSourceBucket3) ReadJSON(legacyTypeNames bool, in *basictl.JsonLexer) error {
	var propFieldsMaskPresented bool
	var rawHeader []byte
	var propTimePresented bool
	var trueTypeHistoricPresented bool
	var trueTypeHistoricValue bool
	var trueTypeSparePresented bool
	var trueTypeSpareValue bool
	var propBuildCommitPresented bool
	var propBuildCommitDatePresented bool
	var propBuildCommitTsPresented bool
	var propQueueSizeDiskPresented bool
	var propQueueSizeMemoryPresented bool
	var propQueueSizeDiskSumPresented bool
	var propQueueSizeMemorySumPresented bool
	var propQueueSizeDiskUnsentPresented bool
	var propQueueSizeDiskSumUnsentPresented bool
	var propOriginalSizePresented bool
	var propCompressedDataPresented bool

	if in != nil {
		in.Delim('{')
		if !in.Ok() {
			return in.Error()
		}
		for !in.IsDelim('}') {
			key := in.UnsafeFieldName(true)
			in.WantColon()
			switch key {
			case "fields_mask":
				if propFieldsMaskPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "fields_mask")
				}
				if err := Json2ReadUint32(in, &item.FieldsMask); err != nil {
					return err
				}
				propFieldsMaskPresented = true
			case "header":
				if rawHeader != nil {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "header")
				}
				rawHeader = in.Raw()
				if !in.Ok() {
					return in.Error()
				}
			case "time":
				if propTimePresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "time")
				}
				if err := Json2ReadUint32(in, &item.Time); err != nil {
					return err
				}
				propTimePresented = true
			case "historic":
				if trueTypeHistoricPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "historic")
				}
				if err := Json2ReadBool(in, &trueTypeHistoricValue); err != nil {
					return err
				}
				trueTypeHistoricPresented = true
			case "spare":
				if trueTypeSparePresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "spare")
				}
				if err := Json2ReadBool(in, &trueTypeSpareValue); err != nil {
					return err
				}
				trueTypeSparePresented = true
			case "build_commit":
				if propBuildCommitPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "build_commit")
				}
				if err := Json2ReadString(in, &item.BuildCommit); err != nil {
					return err
				}
				propBuildCommitPresented = true
			case "build_commit_date":
				if propBuildCommitDatePresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "build_commit_date")
				}
				if err := Json2ReadInt32(in, &item.BuildCommitDate); err != nil {
					return err
				}
				propBuildCommitDatePresented = true
			case "build_commit_ts":
				if propBuildCommitTsPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "build_commit_ts")
				}
				if err := Json2ReadInt32(in, &item.BuildCommitTs); err != nil {
					return err
				}
				propBuildCommitTsPresented = true
			case "queue_size_disk":
				if propQueueSizeDiskPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "queue_size_disk")
				}
				if err := Json2ReadInt32(in, &item.QueueSizeDisk); err != nil {
					return err
				}
				propQueueSizeDiskPresented = true
			case "queue_size_memory":
				if propQueueSizeMemoryPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "queue_size_memory")
				}
				if err := Json2ReadInt32(in, &item.QueueSizeMemory); err != nil {
					return err
				}
				propQueueSizeMemoryPresented = true
			case "queue_size_disk_sum":
				if propQueueSizeDiskSumPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "queue_size_disk_sum")
				}
				if err := Json2ReadInt32(in, &item.QueueSizeDiskSum); err != nil {
					return err
				}
				propQueueSizeDiskSumPresented = true
			case "queue_size_memory_sum":
				if propQueueSizeMemorySumPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "queue_size_memory_sum")
				}
				if err := Json2ReadInt32(in, &item.QueueSizeMemorySum); err != nil {
					return err
				}
				propQueueSizeMemorySumPresented = true
			case "queue_size_disk_unsent":
				if propQueueSizeDiskUnsentPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "queue_size_disk_unsent")
				}
				if err := Json2ReadInt32(in, &item.QueueSizeDiskUnsent); err != nil {
					return err
				}
				propQueueSizeDiskUnsentPresented = true
			case "queue_size_disk_sum_unsent":
				if propQueueSizeDiskSumUnsentPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "queue_size_disk_sum_unsent")
				}
				if err := Json2ReadInt32(in, &item.QueueSizeDiskSumUnsent); err != nil {
					return err
				}
				propQueueSizeDiskSumUnsentPresented = true
			case "original_size":
				if propOriginalSizePresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "original_size")
				}
				if err := Json2ReadUint32(in, &item.OriginalSize); err != nil {
					return err
				}
				propOriginalSizePresented = true
			case "compressed_data":
				if propCompressedDataPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "compressed_data")
				}
				if err := Json2ReadString(in, &item.CompressedData); err != nil {
					return err
				}
				propCompressedDataPresented = true
			default:
				return ErrorInvalidJSONExcessElement("statshouse.sendSourceBucket3", key)
			}
			in.WantComma()
		}
		in.Delim('}')
		if !in.Ok() {
			return in.Error()
		}
	}
	if !propFieldsMaskPresented {
		item.FieldsMask = 0
	}
	if !propTimePresented {
		item.Time = 0
	}
	if !propBuildCommitPresented {
		item.BuildCommit = ""
	}
	if !propBuildCommitDatePresented {
		item.BuildCommitDate = 0
	}
	if !propBuildCommitTsPresented {
		item.BuildCommitTs = 0
	}
	if !propQueueSizeDiskPresented {
		item.QueueSizeDisk = 0
	}
	if !propQueueSizeMemoryPresented {
		item.QueueSizeMemory = 0
	}
	if !propQueueSizeDiskSumPresented {
		item.QueueSizeDiskSum = 0
	}
	if !propQueueSizeMemorySumPresented {
		item.QueueSizeMemorySum = 0
	}
	if !propQueueSizeDiskUnsentPresented {
		item.QueueSizeDiskUnsent = 0
	}
	if !propQueueSizeDiskSumUnsentPresented {
		item.QueueSizeDiskSumUnsent = 0
	}
	if !propOriginalSizePresented {
		item.OriginalSize = 0
	}
	if !propCompressedDataPresented {
		item.CompressedData = ""
	}
	if trueTypeHistoricPresented {
		if trueTypeHistoricValue {
			item.FieldsMask |= 1 << 0
		}
	}
	if trueTypeSparePresented {
		if trueTypeSpareValue {
			item.FieldsMask |= 1 << 1
		}
	}
	if propQueueSizeDiskSumPresented {
		item.FieldsMask |= 1 << 2
	}
	if propQueueSizeMemorySumPresented {
		item.FieldsMask |= 1 << 2
	}
	if propQueueSizeDiskUnsentPresented {
		item.FieldsMask |= 1 << 3
	}
	if propQueueSizeDiskSumUnsentPresented {
		item.FieldsMask |= 1 << 3
	}
	var inHeaderPointer *basictl.JsonLexer
	inHeader := basictl.JsonLexer{Data: rawHeader}
	if rawHeader != nil {
		inHeaderPointer = &inHeader
	}
	if err := item.Header.ReadJSON(legacyTypeNames, inHeaderPointer, item.FieldsMask); err != nil {
		return err
	}

	// tries to set bit to zero if it is 1
	if trueTypeHistoricPresented && !trueTypeHistoricValue && (item.FieldsMask&(1<<0) != 0) {
		return ErrorInvalidJSON("statshouse.sendSourceBucket3", "fieldmask bit fields_mask.0 is indefinite because of the contradictions in values")
	}
	// tries to set bit to zero if it is 1
	if trueTypeSparePresented && !trueTypeSpareValue && (item.FieldsMask&(1<<1) != 0) {
		return ErrorInvalidJSON("statshouse.sendSourceBucket3", "fieldmask bit fields_mask.0 is indefinite because of the contradictions in values")
	}
	return nil
}

// This method is general version of WriteJSON, use it instead!
func (item *StatshouseSendSourceBucket3) WriteJSONGeneral(w []byte) (_ []byte, err error) {
	return item.WriteJSONOpt(true, false, w), nil
}

func (item *StatshouseSendSourceBucket3) WriteJSON(w []byte) []byte {
	return item.WriteJSONOpt(true, false, w)
}
func (item *StatshouseSendSourceBucket3) WriteJSONOpt(newTypeNames bool, short bool, w []byte) []byte {
	w = append(w, '{')
	backupIndexFieldsMask := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"fields_mask":`...)
	w = basictl.JSONWriteUint32(w, item.FieldsMask)
	if (item.FieldsMask != 0) == false {
		w = w[:backupIndexFieldsMask]
	}
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"header":`...)
	w = item.Header.WriteJSONOpt(newTypeNames, short, w, item.FieldsMask)
	backupIndexTime := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"time":`...)
	w = basictl.JSONWriteUint32(w, item.Time)
	if (item.Time != 0) == false {
		w = w[:backupIndexTime]
	}
	if item.FieldsMask&(1<<0) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"historic":true`...)
	}
	if item.FieldsMask&(1<<1) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"spare":true`...)
	}
	backupIndexBuildCommit := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"build_commit":`...)
	w = basictl.JSONWriteString(w, item.BuildCommit)
	if (len(item.BuildCommit) != 0) == false {
		w = w[:backupIndexBuildCommit]
	}
	backupIndexBuildCommitDate := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"build_commit_date":`...)
	w = basictl.JSONWriteInt32(w, item.BuildCommitDate)
	if (item.BuildCommitDate != 0) == false {
		w = w[:backupIndexBuildCommitDate]
	}
	backupIndexBuildCommitTs := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"build_commit_ts":`...)
	w = basictl.JSONWriteInt32(w, item.BuildCommitTs)
	if (item.BuildCommitTs != 0) == false {
		w = w[:backupIndexBuildCommitTs]
	}
	backupIndexQueueSizeDisk := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"queue_size_disk":`...)
	w = basictl.JSONWriteInt32(w, item.QueueSizeDisk)
	if (item.QueueSizeDisk != 0) == false {
		w = w[:backupIndexQueueSizeDisk]
	}
	backupIndexQueueSizeMemory := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"queue_size_memory":`...)
	w = basictl.JSONWriteInt32(w, item.QueueSizeMemory)
	if (item.QueueSizeMemory != 0) == false {
		w = w[:backupIndexQueueSizeMemory]
	}
	if item.FieldsMask&(1<<2) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"queue_size_disk_sum":`...)
		w = basictl.JSONWriteInt32(w, item.QueueSizeDiskSum)
	}
	if item.FieldsMask&(1<<2) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"queue_size_memory_sum":`...)
		w = basictl.JSONWriteInt32(w, item.QueueSizeMemorySum)
	}
	if item.FieldsMask&(1<<3) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"queue_size_disk_unsent":`...)
		w = basictl.JSONWriteInt32(w, item.QueueSizeDiskUnsent)
	}
	if item.FieldsMask&(1<<3) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"queue_size_disk_sum_unsent":`...)
		w = basictl.JSONWriteInt32(w, item.QueueSizeDiskSumUnsent)
	}
	backupIndexOriginalSize := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"original_size":`...)
	w = basictl.JSONWriteUint32(w, item.OriginalSize)
	if (item.OriginalSize != 0) == false {
		w = w[:backupIndexOriginalSize]
	}
	backupIndexCompressedData := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"compressed_data":`...)
	w = basictl.JSONWriteString(w, item.CompressedData)
	if (len(item.CompressedData) != 0) == false {
		w = w[:backupIndexCompressedData]
	}
	return append(w, '}')
}

func (item *StatshouseSendSourceBucket3) MarshalJSON() ([]byte, error) {
	return item.WriteJSON(nil), nil
}

func (item *StatshouseSendSourceBucket3) UnmarshalJSON(b []byte) error {
	if err := item.ReadJSON(true, &basictl.JsonLexer{Data: b}); err != nil {
		return ErrorInvalidJSON("statshouse.sendSourceBucket3", err.Error())
	}
	return nil
}

type StatshouseSendSourceBucket3Bytes struct {
	FieldsMask uint32
	Header     StatshouseCommonProxyHeaderBytes
	Time       uint32
	// Historic (TrueType) // Conditional: item.FieldsMask.0
	// Spare (TrueType) // Conditional: item.FieldsMask.1
	BuildCommit            []byte
	BuildCommitDate        int32
	BuildCommitTs          int32
	QueueSizeDisk          int32
	QueueSizeMemory        int32
	QueueSizeDiskSum       int32 // Conditional: item.FieldsMask.2
	QueueSizeMemorySum     int32 // Conditional: item.FieldsMask.2
	QueueSizeDiskUnsent    int32 // Conditional: item.FieldsMask.3
	QueueSizeDiskSumUnsent int32 // Conditional: item.FieldsMask.3
	OriginalSize           uint32
	CompressedData         []byte
}

func (StatshouseSendSourceBucket3Bytes) TLName() string { return "statshouse.sendSourceBucket3" }
func (StatshouseSendSourceBucket3Bytes) TLTag() uint32  { return 0x0d04aa3f }

func (item *StatshouseSendSourceBucket3Bytes) SetHistoric(v bool) {
	if v {
		item.FieldsMask |= 1 << 0
	} else {
		item.FieldsMask &^= 1 << 0
	}
}
func (item StatshouseSendSourceBucket3Bytes) IsSetHistoric() bool { return item.FieldsMask&(1<<0) != 0 }

func (item *StatshouseSendSourceBucket3Bytes) SetSpare(v bool) {
	if v {
		item.FieldsMask |= 1 << 1
	} else {
		item.FieldsMask &^= 1 << 1
	}
}
func (item StatshouseSendSourceBucket3Bytes) IsSetSpare() bool { return item.FieldsMask&(1<<1) != 0 }

func (item *StatshouseSendSourceBucket3Bytes) SetQueueSizeDiskSum(v int32) {
	item.QueueSizeDiskSum = v
	item.FieldsMask |= 1 << 2
}
func (item *StatshouseSendSourceBucket3Bytes) ClearQueueSizeDiskSum() {
	item.QueueSizeDiskSum = 0
	item.FieldsMask &^= 1 << 2
}
func (item StatshouseSendSourceBucket3Bytes) IsSetQueueSizeDiskSum() bool {
	return item.FieldsMask&(1<<2) != 0
}

func (item *StatshouseSendSourceBucket3Bytes) SetQueueSizeMemorySum(v int32) {
	item.QueueSizeMemorySum = v
	item.FieldsMask |= 1 << 2
}
func (item *StatshouseSendSourceBucket3Bytes) ClearQueueSizeMemorySum() {
	item.QueueSizeMemorySum = 0
	item.FieldsMask &^= 1 << 2
}
func (item StatshouseSendSourceBucket3Bytes) IsSetQueueSizeMemorySum() bool {
	return item.FieldsMask&(1<<2) != 0
}

func (item *StatshouseSendSourceBucket3Bytes) SetQueueSizeDiskUnsent(v int32) {
	item.QueueSizeDiskUnsent = v
	item.FieldsMask |= 1 << 3
}
func (item *StatshouseSendSourceBucket3Bytes) ClearQueueSizeDiskUnsent() {
	item.QueueSizeDiskUnsent = 0
	item.FieldsMask &^= 1 << 3
}
func (item StatshouseSendSourceBucket3Bytes) IsSetQueueSizeDiskUnsent() bool {
	return item.FieldsMask&(1<<3) != 0
}

func (item *StatshouseSendSourceBucket3Bytes) SetQueueSizeDiskSumUnsent(v int32) {
	item.QueueSizeDiskSumUnsent = v
	item.FieldsMask |= 1 << 3
}
func (item *StatshouseSendSourceBucket3Bytes) ClearQueueSizeDiskSumUnsent() {
	item.QueueSizeDiskSumUnsent = 0
	item.FieldsMask &^= 1 << 3
}
func (item StatshouseSendSourceBucket3Bytes) IsSetQueueSizeDiskSumUnsent() bool {
	return item.FieldsMask&(1<<3) != 0
}

func (item *StatshouseSendSourceBucket3Bytes) Reset() {
	item.FieldsMask = 0
	item.Header.Reset()
	item.Time = 0
	item.BuildCommit = item.BuildCommit[:0]
	item.BuildCommitDate = 0
	item.BuildCommitTs = 0
	item.QueueSizeDisk = 0
	item.QueueSizeMemory = 0
	item.QueueSizeDiskSum = 0
	item.QueueSizeMemorySum = 0
	item.QueueSizeDiskUnsent = 0
	item.QueueSizeDiskSumUnsent = 0
	item.OriginalSize = 0
	item.CompressedData = item.CompressedData[:0]
}

func (item *StatshouseSendSourceBucket3Bytes) Read(w []byte) (_ []byte, err error) {
	if w, err = basictl.NatRead(w, &item.FieldsMask); err != nil {
		return w, err
	}
	if w, err = item.Header.Read(w, item.FieldsMask); err != nil {
		return w, err
	}
	if w, err = basictl.NatRead(w, &item.Time); err != nil {
		return w, err
	}
	if w, err = basictl.StringReadBytes(w, &item.BuildCommit); err != nil {
		return w, err
	}
	if w, err = basictl.IntRead(w, &item.BuildCommitDate); err != nil {
		return w, err
	}
	if w, err = basictl.IntRead(w, &item.BuildCommitTs); err != nil {
		return w, err
	}
	if w, err = basictl.IntRead(w, &item.QueueSizeDisk); err != nil {
		return w, err
	}
	if w, err = basictl.IntRead(w, &item.QueueSizeMemory); err != nil {
		return w, err
	}
	if item.FieldsMask&(1<<2) != 0 {
		if w, err = basictl.IntRead(w, &item.QueueSizeDiskSum); err != nil {
			return w, err
		}
	} else {
		item.QueueSizeDiskSum = 0
	}
	if item.FieldsMask&(1<<2) != 0 {
		if w, err = basictl.IntRead(w, &item.QueueSizeMemorySum); err != nil {
			return w, err
		}
	} else {
		item.QueueSizeMemorySum = 0
	}
	if item.FieldsMask&(1<<3) != 0 {
		if w, err = basictl.IntRead(w, &item.QueueSizeDiskUnsent); err != nil {
			return w, err
		}
	} else {
		item.QueueSizeDiskUnsent = 0
	}
	if item.FieldsMask&(1<<3) != 0 {
		if w, err = basictl.IntRead(w, &item.QueueSizeDiskSumUnsent); err != nil {
			return w, err
		}
	} else {
		item.QueueSizeDiskSumUnsent = 0
	}
	if w, err = basictl.NatRead(w, &item.OriginalSize); err != nil {
		return w, err
	}
	return basictl.StringReadBytes(w, &item.CompressedData)
}

// This method is general version of Write, use it instead!
func (item *StatshouseSendSourceBucket3Bytes) WriteGeneral(w []byte) (_ []byte, err error) {
	return item.Write(w), nil
}

func (item *StatshouseSendSourceBucket3Bytes) Write(w []byte) []byte {
	w = basictl.NatWrite(w, item.FieldsMask)
	w = item.Header.Write(w, item.FieldsMask)
	w = basictl.NatWrite(w, item.Time)
	w = basictl.StringWriteBytes(w, item.BuildCommit)
	w = basictl.IntWrite(w, item.BuildCommitDate)
	w = basictl.IntWrite(w, item.BuildCommitTs)
	w = basictl.IntWrite(w, item.QueueSizeDisk)
	w = basictl.IntWrite(w, item.QueueSizeMemory)
	if item.FieldsMask&(1<<2) != 0 {
		w = basictl.IntWrite(w, item.QueueSizeDiskSum)
	}
	if item.FieldsMask&(1<<2) != 0 {
		w = basictl.IntWrite(w, item.QueueSizeMemorySum)
	}
	if item.FieldsMask&(1<<3) != 0 {
		w = basictl.IntWrite(w, item.QueueSizeDiskUnsent)
	}
	if item.FieldsMask&(1<<3) != 0 {
		w = basictl.IntWrite(w, item.QueueSizeDiskSumUnsent)
	}
	w = basictl.NatWrite(w, item.OriginalSize)
	w = basictl.StringWriteBytes(w, item.CompressedData)
	return w
}

func (item *StatshouseSendSourceBucket3Bytes) ReadBoxed(w []byte) (_ []byte, err error) {
	if w, err = basictl.NatReadExactTag(w, 0x0d04aa3f); err != nil {
		return w, err
	}
	return item.Read(w)
}

// This method is general version of WriteBoxed, use it instead!
func (item *StatshouseSendSourceBucket3Bytes) WriteBoxedGeneral(w []byte) (_ []byte, err error) {
	return item.WriteBoxed(w), nil
}

func (item *StatshouseSendSourceBucket3Bytes) WriteBoxed(w []byte) []byte {
	w = basictl.NatWrite(w, 0x0d04aa3f)
	return item.Write(w)
}

func (item *StatshouseSendSourceBucket3Bytes) ReadResult(w []byte, ret *StatshouseSendSourceBucket3ResponseBytes) (_ []byte, err error) {
	return ret.ReadBoxed(w)
}

func (item *StatshouseSendSourceBucket3Bytes) WriteResult(w []byte, ret StatshouseSendSourceBucket3ResponseBytes) (_ []byte, err error) {
	w = ret.WriteBoxed(w)
	return w, nil
}

func (item *StatshouseSendSourceBucket3Bytes) ReadResultJSON(legacyTypeNames bool, in *basictl.JsonLexer, ret *StatshouseSendSourceBucket3ResponseBytes) error {
	if err := ret.ReadJSON(legacyTypeNames, in); err != nil {
		return err
	}
	return nil
}

func (item *StatshouseSendSourceBucket3Bytes) WriteResultJSON(w []byte, ret StatshouseSendSourceBucket3ResponseBytes) (_ []byte, err error) {
	return item.writeResultJSON(true, false, w, ret)
}

func (item *StatshouseSendSourceBucket3Bytes) writeResultJSON(newTypeNames bool, short bool, w []byte, ret StatshouseSendSourceBucket3ResponseBytes) (_ []byte, err error) {
	w = ret.WriteJSONOpt(newTypeNames, short, w)
	return w, nil
}

func (item *StatshouseSendSourceBucket3Bytes) ReadResultWriteResultJSON(r []byte, w []byte) (_ []byte, _ []byte, err error) {
	var ret StatshouseSendSourceBucket3ResponseBytes
	if r, err = item.ReadResult(r, &ret); err != nil {
		return r, w, err
	}
	w, err = item.WriteResultJSON(w, ret)
	return r, w, err
}

func (item *StatshouseSendSourceBucket3Bytes) ReadResultWriteResultJSONOpt(newTypeNames bool, short bool, r []byte, w []byte) (_ []byte, _ []byte, err error) {
	var ret StatshouseSendSourceBucket3ResponseBytes
	if r, err = item.ReadResult(r, &ret); err != nil {
		return r, w, err
	}
	w, err = item.writeResultJSON(newTypeNames, short, w, ret)
	return r, w, err
}

func (item *StatshouseSendSourceBucket3Bytes) ReadResultJSONWriteResult(r []byte, w []byte) ([]byte, []byte, error) {
	var ret StatshouseSendSourceBucket3ResponseBytes
	err := item.ReadResultJSON(true, &basictl.JsonLexer{Data: r}, &ret)
	if err != nil {
		return r, w, err
	}
	w, err = item.WriteResult(w, ret)
	return r, w, err
}

func (item StatshouseSendSourceBucket3Bytes) String() string {
	return string(item.WriteJSON(nil))
}

func (item *StatshouseSendSourceBucket3Bytes) ReadJSON(legacyTypeNames bool, in *basictl.JsonLexer) error {
	var propFieldsMaskPresented bool
	var rawHeader []byte
	var propTimePresented bool
	var trueTypeHistoricPresented bool
	var trueTypeHistoricValue bool
	var trueTypeSparePresented bool
	var trueTypeSpareValue bool
	var propBuildCommitPresented bool
	var propBuildCommitDatePresented bool
	var propBuildCommitTsPresented bool
	var propQueueSizeDiskPresented bool
	var propQueueSizeMemoryPresented bool
	var propQueueSizeDiskSumPresented bool
	var propQueueSizeMemorySumPresented bool
	var propQueueSizeDiskUnsentPresented bool
	var propQueueSizeDiskSumUnsentPresented bool
	var propOriginalSizePresented bool
	var propCompressedDataPresented bool

	if in != nil {
		in.Delim('{')
		if !in.Ok() {
			return in.Error()
		}
		for !in.IsDelim('}') {
			key := in.UnsafeFieldName(true)
			in.WantColon()
			switch key {
			case "fields_mask":
				if propFieldsMaskPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "fields_mask")
				}
				if err := Json2ReadUint32(in, &item.FieldsMask); err != nil {
					return err
				}
				propFieldsMaskPresented = true
			case "header":
				if rawHeader != nil {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "header")
				}
				rawHeader = in.Raw()
				if !in.Ok() {
					return in.Error()
				}
			case "time":
				if propTimePresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "time")
				}
				if err := Json2ReadUint32(in, &item.Time); err != nil {
					return err
				}
				propTimePresented = true
			case "historic":
				if trueTypeHistoricPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "historic")
				}
				if err := Json2ReadBool(in, &trueTypeHistoricValue); err != nil {
					return err
				}
				trueTypeHistoricPresented = true
			case "spare":
				if trueTypeSparePresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "spare")
				}
				if err := Json2ReadBool(in, &trueTypeSpareValue); err != nil {
					return err
				}
				trueTypeSparePresented = true
			case "build_commit":
				if propBuildCommitPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "build_commit")
				}
				if err := Json2ReadStringBytes(in, &item.BuildCommit); err != nil {
					return err
				}
				propBuildCommitPresented = true
			case "build_commit_date":
				if propBuildCommitDatePresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "build_commit_date")
				}
				if err := Json2ReadInt32(in, &item.BuildCommitDate); err != nil {
					return err
				}
				propBuildCommitDatePresented = true
			case "build_commit_ts":
				if propBuildCommitTsPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "build_commit_ts")
				}
				if err := Json2ReadInt32(in, &item.BuildCommitTs); err != nil {
					return err
				}
				propBuildCommitTsPresented = true
			case "queue_size_disk":
				if propQueueSizeDiskPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "queue_size_disk")
				}
				if err := Json2ReadInt32(in, &item.QueueSizeDisk); err != nil {
					return err
				}
				propQueueSizeDiskPresented = true
			case "queue_size_memory":
				if propQueueSizeMemoryPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "queue_size_memory")
				}
				if err := Json2ReadInt32(in, &item.QueueSizeMemory); err != nil {
					return err
				}
				propQueueSizeMemoryPresented = true
			case "queue_size_disk_sum":
				if propQueueSizeDiskSumPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "queue_size_disk_sum")
				}
				if err := Json2ReadInt32(in, &item.QueueSizeDiskSum); err != nil {
					return err
				}
				propQueueSizeDiskSumPresented = true
			case "queue_size_memory_sum":
				if propQueueSizeMemorySumPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "queue_size_memory_sum")
				}
				if err := Json2ReadInt32(in, &item.QueueSizeMemorySum); err != nil {
					return err
				}
				propQueueSizeMemorySumPresented = true
			case "queue_size_disk_unsent":
				if propQueueSizeDiskUnsentPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "queue_size_disk_unsent")
				}
				if err := Json2ReadInt32(in, &item.QueueSizeDiskUnsent); err != nil {
					return err
				}
				propQueueSizeDiskUnsentPresented = true
			case "queue_size_disk_sum_unsent":
				if propQueueSizeDiskSumUnsentPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "queue_size_disk_sum_unsent")
				}
				if err := Json2ReadInt32(in, &item.QueueSizeDiskSumUnsent); err != nil {
					return err
				}
				propQueueSizeDiskSumUnsentPresented = true
			case "original_size":
				if propOriginalSizePresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "original_size")
				}
				if err := Json2ReadUint32(in, &item.OriginalSize); err != nil {
					return err
				}
				propOriginalSizePresented = true
			case "compressed_data":
				if propCompressedDataPresented {
					return ErrorInvalidJSONWithDuplicatingKeys("statshouse.sendSourceBucket3", "compressed_data")
				}
				if err := Json2ReadStringBytes(in, &item.CompressedData); err != nil {
					return err
				}
				propCompressedDataPresented = true
			default:
				return ErrorInvalidJSONExcessElement("statshouse.sendSourceBucket3", key)
			}
			in.WantComma()
		}
		in.Delim('}')
		if !in.Ok() {
			return in.Error()
		}
	}
	if !propFieldsMaskPresented {
		item.FieldsMask = 0
	}
	if !propTimePresented {
		item.Time = 0
	}
	if !propBuildCommitPresented {
		item.BuildCommit = item.BuildCommit[:0]
	}
	if !propBuildCommitDatePresented {
		item.BuildCommitDate = 0
	}
	if !propBuildCommitTsPresented {
		item.BuildCommitTs = 0
	}
	if !propQueueSizeDiskPresented {
		item.QueueSizeDisk = 0
	}
	if !propQueueSizeMemoryPresented {
		item.QueueSizeMemory = 0
	}
	if !propQueueSizeDiskSumPresented {
		item.QueueSizeDiskSum = 0
	}
	if !propQueueSizeMemorySumPresented {
		item.QueueSizeMemorySum = 0
	}
	if !propQueueSizeDiskUnsentPresented {
		item.QueueSizeDiskUnsent = 0
	}
	if !propQueueSizeDiskSumUnsentPresented {
		item.QueueSizeDiskSumUnsent = 0
	}
	if !propOriginalSizePresented {
		item.OriginalSize = 0
	}
	if !propCompressedDataPresented {
		item.CompressedData = item.CompressedData[:0]
	}
	if trueTypeHistoricPresented {
		if trueTypeHistoricValue {
			item.FieldsMask |= 1 << 0
		}
	}
	if trueTypeSparePresented {
		if trueTypeSpareValue {
			item.FieldsMask |= 1 << 1
		}
	}
	if propQueueSizeDiskSumPresented {
		item.FieldsMask |= 1 << 2
	}
	if propQueueSizeMemorySumPresented {
		item.FieldsMask |= 1 << 2
	}
	if propQueueSizeDiskUnsentPresented {
		item.FieldsMask |= 1 << 3
	}
	if propQueueSizeDiskSumUnsentPresented {
		item.FieldsMask |= 1 << 3
	}
	var inHeaderPointer *basictl.JsonLexer
	inHeader := basictl.JsonLexer{Data: rawHeader}
	if rawHeader != nil {
		inHeaderPointer = &inHeader
	}
	if err := item.Header.ReadJSON(legacyTypeNames, inHeaderPointer, item.FieldsMask); err != nil {
		return err
	}

	// tries to set bit to zero if it is 1
	if trueTypeHistoricPresented && !trueTypeHistoricValue && (item.FieldsMask&(1<<0) != 0) {
		return ErrorInvalidJSON("statshouse.sendSourceBucket3", "fieldmask bit fields_mask.0 is indefinite because of the contradictions in values")
	}
	// tries to set bit to zero if it is 1
	if trueTypeSparePresented && !trueTypeSpareValue && (item.FieldsMask&(1<<1) != 0) {
		return ErrorInvalidJSON("statshouse.sendSourceBucket3", "fieldmask bit fields_mask.0 is indefinite because of the contradictions in values")
	}
	return nil
}

// This method is general version of WriteJSON, use it instead!
func (item *StatshouseSendSourceBucket3Bytes) WriteJSONGeneral(w []byte) (_ []byte, err error) {
	return item.WriteJSONOpt(true, false, w), nil
}

func (item *StatshouseSendSourceBucket3Bytes) WriteJSON(w []byte) []byte {
	return item.WriteJSONOpt(true, false, w)
}
func (item *StatshouseSendSourceBucket3Bytes) WriteJSONOpt(newTypeNames bool, short bool, w []byte) []byte {
	w = append(w, '{')
	backupIndexFieldsMask := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"fields_mask":`...)
	w = basictl.JSONWriteUint32(w, item.FieldsMask)
	if (item.FieldsMask != 0) == false {
		w = w[:backupIndexFieldsMask]
	}
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"header":`...)
	w = item.Header.WriteJSONOpt(newTypeNames, short, w, item.FieldsMask)
	backupIndexTime := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"time":`...)
	w = basictl.JSONWriteUint32(w, item.Time)
	if (item.Time != 0) == false {
		w = w[:backupIndexTime]
	}
	if item.FieldsMask&(1<<0) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"historic":true`...)
	}
	if item.FieldsMask&(1<<1) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"spare":true`...)
	}
	backupIndexBuildCommit := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"build_commit":`...)
	w = basictl.JSONWriteStringBytes(w, item.BuildCommit)
	if (len(item.BuildCommit) != 0) == false {
		w = w[:backupIndexBuildCommit]
	}
	backupIndexBuildCommitDate := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"build_commit_date":`...)
	w = basictl.JSONWriteInt32(w, item.BuildCommitDate)
	if (item.BuildCommitDate != 0) == false {
		w = w[:backupIndexBuildCommitDate]
	}
	backupIndexBuildCommitTs := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"build_commit_ts":`...)
	w = basictl.JSONWriteInt32(w, item.BuildCommitTs)
	if (item.BuildCommitTs != 0) == false {
		w = w[:backupIndexBuildCommitTs]
	}
	backupIndexQueueSizeDisk := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"queue_size_disk":`...)
	w = basictl.JSONWriteInt32(w, item.QueueSizeDisk)
	if (item.QueueSizeDisk != 0) == false {
		w = w[:backupIndexQueueSizeDisk]
	}
	backupIndexQueueSizeMemory := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"queue_size_memory":`...)
	w = basictl.JSONWriteInt32(w, item.QueueSizeMemory)
	if (item.QueueSizeMemory != 0) == false {
		w = w[:backupIndexQueueSizeMemory]
	}
	if item.FieldsMask&(1<<2) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"queue_size_disk_sum":`...)
		w = basictl.JSONWriteInt32(w, item.QueueSizeDiskSum)
	}
	if item.FieldsMask&(1<<2) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"queue_size_memory_sum":`...)
		w = basictl.JSONWriteInt32(w, item.QueueSizeMemorySum)
	}
	if item.FieldsMask&(1<<3) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"queue_size_disk_unsent":`...)
		w = basictl.JSONWriteInt32(w, item.QueueSizeDiskUnsent)
	}
	if item.FieldsMask&(1<<3) != 0 {
		w = basictl.JSONAddCommaIfNeeded(w)
		w = append(w, `"queue_size_disk_sum_unsent":`...)
		w = basictl.JSONWriteInt32(w, item.QueueSizeDiskSumUnsent)
	}
	backupIndexOriginalSize := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"original_size":`...)
	w = basictl.JSONWriteUint32(w, item.OriginalSize)
	if (item.OriginalSize != 0) == false {
		w = w[:backupIndexOriginalSize]
	}
	backupIndexCompressedData := len(w)
	w = basictl.JSONAddCommaIfNeeded(w)
	w = append(w, `"compressed_data":`...)
	w = basictl.JSONWriteStringBytes(w, item.CompressedData)
	if (len(item.CompressedData) != 0) == false {
		w = w[:backupIndexCompressedData]
	}
	return append(w, '}')
}

func (item *StatshouseSendSourceBucket3Bytes) MarshalJSON() ([]byte, error) {
	return item.WriteJSON(nil), nil
}

func (item *StatshouseSendSourceBucket3Bytes) UnmarshalJSON(b []byte) error {
	if err := item.ReadJSON(true, &basictl.JsonLexer{Data: b}); err != nil {
		return ErrorInvalidJSON("statshouse.sendSourceBucket3", err.Error())
	}
	return nil
}
